{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e326d5f",
   "metadata": {},
   "source": [
    "# The importance of appropriate cross-validation\n",
    "\n",
    "\n",
    "In using machine learning on neuroimaging data, appropriate cross-validation methods are critical for drawing meaningful inferences.\n",
    "However, a majority of neuroscience researchers are not familiar with how to choose an appropriate method for their data.\n",
    "\n",
    "```{figure} ../images/poldrack-2020-fig3.jpg\n",
    "---\n",
    "height: 350px\n",
    "name: cv-usage\n",
    "---\n",
    "Figure 3 from {cite}`Poldrack_2020`, depicting esults from a review of 100 Studies (2017‚Äì2019) claiming prediction on fMRI Data\n",
    "Panel A shows prevalence of cross-validation methods used to assess predictive accuracy in this sample.\n",
    "Panel B shows a histogram of associated sample sizes.\n",
    "```\n",
    "\n",
    "First, we can formalize the problem to let us give a formalism for confounding structures.\n",
    "We adopt the notation used in {cite}`Little_2017`\n",
    "For $N$ observations, we consider a variable $y \\in \\mathbb{R}^n$ that we are trying to predict from data $X \\in \\mathbb{R}^{n \\times p}$ in the presence of confounds $Z \\in \\mathbb{R}^{n \\times k}$‚Å†. \n",
    "\n",
    "y is then a function of X and Z:\n",
    "\n",
    "$$\n",
    "  y = f(XZ) + \\epsilon\n",
    "$$\n",
    "\n",
    "for linear associations:\n",
    "\n",
    "$$\n",
    "  y = Xw + Zu + \\epsilon\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is observation noise. In such model, $\\epsilon$ may be i.i.d. even though the relationship between $y$ and $X$ is not i.i.d, e.g., changing from subject to subject \n",
    "\n",
    "The machine learning problem is to estimate from train data {train} = (ytrainXtrain) a function fÃÇ {train} that predicts best y from X. In other words, we want to minimize an error Óà±(y,fÃÇ (X))‚Å†. The purpose of cross-validation is to estimate this error. \n",
    "\n",
    "The challenge is that we are interested in the error on new, unknown, data, i.e. the expectancy of the error for (y, X) drawn from their unknown distribution: ùîº(y,X)[Óà±(y,fÃÇ (X))] [2]. This is why evaluation procedures must test predictions of the model on left-out data that should be independent from the data used to train the model.\n",
    "\n",
    "```{figure} ../images/varoquaux-2016-fig6.jpg\n",
    "---\n",
    "height: 350px\n",
    "name: cv-strategies\n",
    "---\n",
    "Figure 6 from {cite}`Varoquaux_2016`.\n",
    "This figures shows the difference in accuracy measured by cross-validation and on the held-out\n",
    "validation set, in intra and inter-subject settings, for different cross-validation strategies:\n",
    "- leave one sample out,\n",
    "- leave one block of samples out (where the block is the natural unit of the experiment: subject or\n",
    "session)\n",
    "- random splits leaving out 20% of the blocks as test data, with 3, 10, or 50 random splits. \n",
    "For inter-subject settings, leave one sample out corresponds to leaving a session out.\n",
    "The box gives the quartiles, while the whiskers give the 5 and 95 percentiles.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7ba966",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b16252",
   "metadata": {},
   "source": [
    "Now that we've seen how to create a connectome for an individual subject,\n",
    "we're ready to think about how we can use this connectome in a machine learning analysis.\n",
    "We'll keep working with the same `development_dataset`,\n",
    "but now we'd like to see if we can predict age group\n",
    "(i.e. whether a participant is a child or adult) based on their connectome,\n",
    "as defined by the functional connectivity matrix.\n",
    "\n",
    "We'll also explore whether we're more or less accurate in our predictions based on how we define functional connectivity.\n",
    "In this example, we'll consider three different different ways to define functional connectivity\n",
    "between our Multi-Subject Dictional Learning (MSDL) regions of interest (ROIs):\n",
    "correlation, partial correlation, and tangent space embedding.\n",
    "\n",
    "To learn more about tangent space embedding and how it compares to standard correlations,\n",
    "we recommend {cite}`Dadi_2019`.\n",
    "\n",
    "## Load brain development fMRI dataset and MSDL atlas\n",
    "\n",
    "First, we need to set up our minimal environment.\n",
    "This will include all the dependencies from the last notebook,\n",
    "loading the relevant data using our `nilearn` data set fetchers,\n",
    "and instantiated our `NiftiMapsMasker` and `ConnectivityMeasure` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e5e02b",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/nilearn/__init__.py:67: FutureWarning: Python 3.7 support is deprecated and will be removed in release 0.12 of Nilearn. Consider switching to Python 3.9 or 3.10.\n",
      "  _python_deprecation_warnings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb47056353c58001c9ac064/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb46e5af2be3c001801f799/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb4703bf2be3c001801fa49/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb46e92a3bc970019f0717f/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff38c4712b4001a3b5573/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff38da743a900176080a2/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb47016a3bc970017efe44f/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb46e43f2be3c0017056b8a/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb470413992690018133d8c/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb46e9a353c58001c9abeac/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff38f2286e80018c3e38d/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3914712b4001a3b5579/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloaded 4202496 of 6020576 bytes (69.8%,    0.5s remaining) ...done. (3 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb4702a353c58001b9cb5ae/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb46e9b39926900190fad5c/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff391a743a900176080a9/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3914712b400173b5329/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb47023353c58001c9ac02b/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb46eaa39926900160f69af/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3912286e80018c3e393/ ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1875/78225428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectome\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnectivityMeasure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdevelopment_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_development_fmri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_subjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmsdl_atlas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_atlas_msdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/nilearn/datasets/func.py\u001b[0m in \u001b[0;36mfetch_development_fmri\u001b[0;34m(n_subjects, reduce_confounds, data_dir, resume, verbose, age_group)\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2003\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2004\u001b[0m     )\n\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/nilearn/datasets/func.py\u001b[0m in \u001b[0;36m_fetch_development_fmri_functional\u001b[0;34m(participants, data_dir, url, resume, verbose)\u001b[0m\n\u001b[1;32m   1847\u001b[0m         ]\n\u001b[1;32m   1848\u001b[0m         path_to_regressor = _fetch_files(\n\u001b[0;32m-> 1849\u001b[0;31m             \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressor_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m         )[0]\n\u001b[1;32m   1851\u001b[0m         \u001b[0mregressors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_regressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/nilearn/datasets/utils.py\u001b[0m in \u001b[0;36m_fetch_files\u001b[0;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m             )\n\u001b[1;32m    793\u001b[0m     \u001b[0;31m# There are two working directories here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/nilearn/datasets/utils.py\u001b[0m in \u001b[0;36m_fetch_files\u001b[0;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"password\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                 \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m             )\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"move\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/nilearn/datasets/utils.py\u001b[0m in \u001b[0;36m_fetch_file\u001b[0;34m(url, data_dir, resume, overwrite, md5sum, username, password, verbose, session)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mprepped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             with session.send(\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0mprepped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_REQUESTS_TIMEOUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m             ) as resp:\n\u001b[1;32m    665\u001b[0m                 \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                     \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0madapter_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                 )\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mpreload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m             )\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.17/x64/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import (datasets, maskers, plotting)\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "development_dataset = datasets.fetch_development_fmri(n_subjects=30)\n",
    "msdl_atlas = datasets.fetch_atlas_msdl()\n",
    "\n",
    "masker = maskers.NiftiMapsMasker(\n",
    "    msdl_atlas.maps, resampling_target=\"data\",\n",
    "    t_r=2, detrend=True,\n",
    "    low_pass=0.1, high_pass=0.01).fit()\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8eae1",
   "metadata": {},
   "source": [
    "Now we should have a much better idea what each line above is doing!\n",
    "Let's see how we can use these objects across many subjects,\n",
    "not just the first one.\n",
    "\n",
    "## Region signals extraction\n",
    "\n",
    "First, we can loop through the 30 participants and extract a few relevant pieces of information,\n",
    "including their functional scan, their confounds file,\n",
    "and whether they were a child or adult at the time of their scan.\n",
    "\n",
    "Using this information, we can then transform their data using the `NiftiMapsMasker` we created above.\n",
    "As we learned last time, it's really important to correct for known sources of noise!\n",
    "So we'll also pass the relevant confounds file directly to the masker object to clean up each subject's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "children = []\n",
    "pooled_subjects = []\n",
    "groups = []  # child or adult\n",
    "\n",
    "for func_file, confound_file, phenotypic in zip(\n",
    "        development_dataset.func,\n",
    "        development_dataset.confounds,\n",
    "        development_dataset.phenotypic):\n",
    "\n",
    "    time_series = masker.transform(func_file, confounds=confound_file)\n",
    "    pooled_subjects.append(time_series)\n",
    "\n",
    "    if phenotypic['Child_Adult'] == 'child':\n",
    "        children.append(time_series)\n",
    "\n",
    "    groups.append(phenotypic['Child_Adult'])\n",
    "\n",
    "print('Data has {0} children.'.format(len(children)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b56f0",
   "metadata": {},
   "source": [
    "We can see that this data set has 24 children.\n",
    "This is roughly proportional to the original participant pool,\n",
    "which had 122 children and 33 adults.\n",
    "\n",
    "We've also created a list in `pooled_subjects` containing all of the cleaned data.\n",
    "Remember that each entry of that list should have a shape of (168, 39).\n",
    "We can quickly confirm that this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23482bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pooled_subjects[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0ca28",
   "metadata": {},
   "source": [
    "## ROI-to-ROI correlations of children\n",
    "\n",
    "First, we'll use the most common kind of connectivity--and the one we used in the last section--correlation.\n",
    "It models the full (marginal) connectivity between pairwise ROIs.\n",
    "\n",
    "`correlation_measure` expects a list of time series,\n",
    "so we can directly supply the list of ROI time series we just created.\n",
    "It will then compute individual correlation matrices for each subject.\n",
    "First, let's just look at the correlation matrices for our 24 children,\n",
    "since we expect these matrices to be similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f871a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrices = correlation_measure.fit_transform(children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556f36a",
   "metadata": {},
   "source": [
    "Now, all individual coefficients are stacked in a unique 2D matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176134ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlations of children are stacked in an array of shape {0}'\n",
    "      .format(correlation_matrices.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900fbfc",
   "metadata": {},
   "source": [
    "We can also directly access the average correlation across all fitted subjects using the `mean_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d09be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_correlation_matrix = correlation_measure.mean_\n",
    "print('Mean correlation has shape {0}.'.format(mean_correlation_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8e2f3",
   "metadata": {},
   "source": [
    "Let's display the functional connectivity matrices of the first 3 children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (matrix, ax) in enumerate(zip(correlation_matrices, axes)):\n",
    "    plotting.plot_matrix(matrix, colorbar=False, axes=ax,\n",
    "                         vmin=-0.8, vmax=0.8,\n",
    "                         title='correlation, child {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8020e96",
   "metadata": {},
   "source": [
    "Just as before, we can also display connectome on the brain.\n",
    "Here, let's show the mean connectome over all 24 children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_connectome(mean_correlation_matrix, msdl_atlas.region_coords,\n",
    "                         edge_threshold=0.2,\n",
    "                         title='mean connectome over all children')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb70e19",
   "metadata": {},
   "source": [
    "## Studying partial correlations\n",
    "\n",
    "Rather than looking at the correlation-defined functional connectivity matrix,\n",
    "we can also study **direct connections** as revealed by partial correlation coefficients.\n",
    "\n",
    "To do this, we can use exactly the same procedure as above, just changing the `ConnectivityMeasure` kind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_correlation_measure = ConnectivityMeasure(kind='partial correlation')\n",
    "partial_correlation_matrices = partial_correlation_measure.fit_transform(\n",
    "    children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f93d49",
   "metadata": {},
   "source": [
    "Right away, we can see that most of direct connections are weaker than full connections for the first three children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (matrix, ax) in enumerate(zip(partial_correlation_matrices, axes)):\n",
    "    plotting.plot_matrix(matrix, colorbar=False, axes=ax,\n",
    "                         vmin=-0.8, vmax=0.8,\n",
    "                         title='partial correlation, child {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23d360",
   "metadata": {},
   "source": [
    "This is also visible when we display the mean partial correlation connectome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_connectome(\n",
    "    partial_correlation_measure.mean_, msdl_atlas.region_coords,\n",
    "    edge_threshold=0.2,\n",
    "    title='mean partial correlation over all children')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924976c3",
   "metadata": {},
   "source": [
    "## Using tangent space embedding\n",
    "\n",
    "An alternative method to both correlations and partial correlation is tangent space embedding.\n",
    "Tangent space embedding uses **both** correlations and partial correlations to capture\n",
    "reproducible connectivity patterns at the group-level.\n",
    "\n",
    "Using this method is as easy as changing the kind of `ConnectivityMeasure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "tangent_measure = ConnectivityMeasure(kind='tangent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33de6e",
   "metadata": {},
   "source": [
    "We fit our children group and get the group connectivity matrix stored as\n",
    "in `tangent_measure.mean_`, and individual deviation matrices of each subject\n",
    "from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeeab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tangent_matrices = tangent_measure.fit_transform(children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5f3b4",
   "metadata": {},
   "source": [
    "`tangent_matrices` model individual connectivities as\n",
    "**perturbations** of the group connectivity matrix `tangent_measure.mean_`.\n",
    "Keep in mind that these subjects-to-group variability matrices do not\n",
    "directly reflect individual brain connections. For instance negative\n",
    "coefficients can not be interpreted as anticorrelated regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (matrix, ax) in enumerate(zip(tangent_matrices, axes)):\n",
    "    plotting.plot_matrix(matrix, colorbar=False, axes=ax,\n",
    "                         vmin=-0.8, vmax=0.8,\n",
    "                         title='tangent offset, child {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6deae",
   "metadata": {},
   "source": [
    "We don't show the mean connectome here as average tangent matrix cannot be interpreted,\n",
    "since individual matrices represent deviations from the mean, which is set to 0.\n",
    "\n",
    "## Using connectivity in a classification analysis\n",
    "\n",
    "We can use these connectivity matrices as features in a classification analysis to distinguish children from adults.\n",
    "This classification analysis can be implmented directly in scikit-learn,\n",
    "including all of the important considerations like cross-validation and measuring classification accuracy.\n",
    "\n",
    "First, we'll randomly split participants into training and testing sets 15 times.\n",
    "`StratifiedShuffleSplit` allows us to preserve the proportion of children-to-adults in the test set.\n",
    "We'll also compute classification accuracies for each of the kinds of functional connectivity we've identified:\n",
    "correlation, partial correlation, and tangent space embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "kinds = ['correlation', 'partial correlation', 'tangent']\n",
    "_, classes = np.unique(groups, return_inverse=True)\n",
    "cv = StratifiedShuffleSplit(n_splits=15, random_state=0, test_size=5)\n",
    "pooled_subjects = np.asarray(pooled_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56e95c",
   "metadata": {},
   "source": [
    "Now, we can train the scikit-learn `LinearSVC` estimator to on our training set of participants\n",
    "and apply the trained classifier on our testing set,\n",
    "storing accuracy scores after each cross-validation fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06254c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for kind in kinds:\n",
    "    scores[kind] = []\n",
    "    for train, test in cv.split(pooled_subjects, classes):\n",
    "        # *ConnectivityMeasure* can output the estimated subjects coefficients\n",
    "        # as a 1D arrays through the parameter *vectorize*.\n",
    "        connectivity = ConnectivityMeasure(kind=kind, vectorize=True)\n",
    "        # build vectorized connectomes for subjects in the train set\n",
    "        connectomes = connectivity.fit_transform(pooled_subjects[train])\n",
    "        # fit the classifier\n",
    "        classifier = LinearSVC().fit(connectomes, classes[train])\n",
    "        # make predictions for the left-out test subjects\n",
    "        predictions = classifier.predict(\n",
    "            connectivity.transform(pooled_subjects[test]))\n",
    "        # store the accuracy for this cross-validation fold\n",
    "        scores[kind].append(accuracy_score(classes[test], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020081ed",
   "metadata": {},
   "source": [
    "After we've done this for all of the folds, we can display the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = [np.mean(scores[kind]) for kind in kinds]\n",
    "scores_std = [np.std(scores[kind]) for kind in kinds]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "positions = np.arange(len(kinds)) * .1 + .1\n",
    "plt.barh(positions, mean_scores, align='center', height=.05, xerr=scores_std)\n",
    "yticks = [k.replace(' ', '\\n') for k in kinds]\n",
    "plt.yticks(positions, yticks)\n",
    "plt.gca().grid(True)\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.gca().axvline(.8, color='red', linestyle='--')\n",
    "plt.xlabel('Classification accuracy\\n(red line = chance level)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5288b9",
   "metadata": {},
   "source": [
    "This is a small example to showcase nilearn features. In practice such\n",
    "comparisons need to be performed on much larger cohorts and several\n",
    "datasets.\n",
    "{cite}`Dadi_2019` showed that across many cohorts and clinical questions,\n",
    "the tangent kind should be preferred.\n",
    "\n",
    "Combining nilearn and scikit-learn can allow us to perform many (many) kinds of machine learning analyses,\n",
    "not just classification!\n",
    "We encourage you to explore the [Examples](http://nilearn.github.io/auto_examples/index.html) and\n",
    "[User Guides](http://nilearn.github.io/user_guide.html) on [the Nilearn website](http://nilearn.github.io) to learn more!\n",
    "\n",
    "```{bibliography} references.bib\n",
    ":style: unsrt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  },
  "repository": {
   "url": "https://github.com/emdupre/nha-ml-nimg"
  },
  "source_map": [
   10,
   66,
   71,
   95,
   110,
   126,
   145,
   155,
   157,
   170,
   172,
   176,
   179,
   183,
   186,
   190,
   196,
   201,
   205,
   214,
   218,
   222,
   228,
   232,
   237,
   247,
   249,
   255,
   257,
   265,
   271,
   287,
   296,
   302,
   319,
   323,
   337
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}