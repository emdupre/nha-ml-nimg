{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffdc8f2b",
   "metadata": {},
   "source": [
    "# An introduction to [`nilearn`](http://nilearn.github.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7eb649",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853cb359",
   "metadata": {},
   "source": [
    "In this tutorial,\n",
    "we'll see how the Python library `nilearn` allows us to easily perform machine learning analyses with neuroimaging data,\n",
    "specifically MRI and fMRI.\n",
    "\n",
    "You may notice that the name `nilearn` is reminiscent of [`scikit-learn`](https://scikit-learn.org),\n",
    "a popular Python library for machine learning.\n",
    "This is no accident!\n",
    "Nilearn and scikit-learn were created by the same team,\n",
    "and nilearn is designed to bring machine **LEARN**ing to the NeuroImaging (**NI**) domain.\n",
    "\n",
    "With that in mind,\n",
    "let's briefly consider why we might want specialized tools for working with neuroimaging data.\n",
    "When performing a machine learning analysis, our data often look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978b2c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>subject</th>\n",
       "      <th>age</th>\n",
       "      <th>age_resid</th>\n",
       "      <th>sex</th>\n",
       "      <th>group</th>\n",
       "      <th>fsArea_L_V1_ROI</th>\n",
       "      <th>fsArea_L_MST_ROI</th>\n",
       "      <th>fsArea_L_V6_ROI</th>\n",
       "      <th>fsArea_L_V2_ROI</th>\n",
       "      <th>...</th>\n",
       "      <th>fsCT_R_p47r_ROI</th>\n",
       "      <th>fsCT_R_TGv_ROI</th>\n",
       "      <th>fsCT_R_MBelt_ROI</th>\n",
       "      <th>fsCT_R_LBelt_ROI</th>\n",
       "      <th>fsCT_R_A4_ROI</th>\n",
       "      <th>fsCT_R_STSva_ROI</th>\n",
       "      <th>fsCT_R_TE1m_ROI</th>\n",
       "      <th>fsCT_R_PI_ROI</th>\n",
       "      <th>fsCT_R_a32pr_ROI</th>\n",
       "      <th>fsCT_R_p24_ROI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABIDEII-KKI_1</td>\n",
       "      <td>29293</td>\n",
       "      <td>8.893151</td>\n",
       "      <td>13.642852</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.362</td>\n",
       "      <td>2.827</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.526</td>\n",
       "      <td>3.202</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.354</td>\n",
       "      <td>2.629</td>\n",
       "      <td>2.699</td>\n",
       "      <td>3.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABIDEII-OHSU_1</td>\n",
       "      <td>28997</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.081732</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.809</td>\n",
       "      <td>3.539</td>\n",
       "      <td>2.944</td>\n",
       "      <td>2.769</td>\n",
       "      <td>3.530</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.282</td>\n",
       "      <td>2.670</td>\n",
       "      <td>2.746</td>\n",
       "      <td>3.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABIDEII-GU_1</td>\n",
       "      <td>28845</td>\n",
       "      <td>8.390000</td>\n",
       "      <td>12.866264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3394.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>2827.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.435</td>\n",
       "      <td>3.321</td>\n",
       "      <td>2.799</td>\n",
       "      <td>2.388</td>\n",
       "      <td>3.148</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.116</td>\n",
       "      <td>2.891</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABIDEII-NYU_1</td>\n",
       "      <td>29210</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>13.698139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3382.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>2686.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.349</td>\n",
       "      <td>3.344</td>\n",
       "      <td>2.694</td>\n",
       "      <td>3.030</td>\n",
       "      <td>3.258</td>\n",
       "      <td>2.774</td>\n",
       "      <td>3.383</td>\n",
       "      <td>2.696</td>\n",
       "      <td>3.014</td>\n",
       "      <td>3.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABIDEII-EMC_1</td>\n",
       "      <td>29894</td>\n",
       "      <td>7.772758</td>\n",
       "      <td>14.772459</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.940</td>\n",
       "      <td>2.809</td>\n",
       "      <td>2.607</td>\n",
       "      <td>3.430</td>\n",
       "      <td>2.752</td>\n",
       "      <td>2.645</td>\n",
       "      <td>3.111</td>\n",
       "      <td>3.219</td>\n",
       "      <td>4.128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1446 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             site  subject        age  age_resid  sex  group  fsArea_L_V1_ROI  \\\n",
       "0   ABIDEII-KKI_1    29293   8.893151  13.642852  2.0    1.0           2750.0   \n",
       "1  ABIDEII-OHSU_1    28997  12.000000  16.081732  2.0    1.0           2836.0   \n",
       "2    ABIDEII-GU_1    28845   8.390000  12.866264  1.0    2.0           3394.0   \n",
       "3   ABIDEII-NYU_1    29210   8.300000  13.698139  1.0    1.0           3382.0   \n",
       "4   ABIDEII-EMC_1    29894   7.772758  14.772459  2.0    2.0           3080.0   \n",
       "\n",
       "   fsArea_L_MST_ROI  fsArea_L_V6_ROI  fsArea_L_V2_ROI  ...  fsCT_R_p47r_ROI  \\\n",
       "0             306.0            354.0           2123.0  ...            3.362   \n",
       "1             186.0            354.0           2261.0  ...            2.809   \n",
       "2             223.0            373.0           2827.0  ...            2.435   \n",
       "3             266.0            422.0           2686.0  ...            3.349   \n",
       "4             161.0            346.0           2105.0  ...            2.428   \n",
       "\n",
       "   fsCT_R_TGv_ROI  fsCT_R_MBelt_ROI  fsCT_R_LBelt_ROI  fsCT_R_A4_ROI  \\\n",
       "0           2.827             2.777             2.526          3.202   \n",
       "1           3.539             2.944             2.769          3.530   \n",
       "2           3.321             2.799             2.388          3.148   \n",
       "3           3.344             2.694             3.030          3.258   \n",
       "4           2.940             2.809             2.607          3.430   \n",
       "\n",
       "   fsCT_R_STSva_ROI  fsCT_R_TE1m_ROI  fsCT_R_PI_ROI  fsCT_R_a32pr_ROI  \\\n",
       "0             3.024            3.354          2.629             2.699   \n",
       "1             3.079            3.282          2.670             2.746   \n",
       "2             3.125            3.116          2.891             2.940   \n",
       "3             2.774            3.383          2.696             3.014   \n",
       "4             2.752            2.645          3.111             3.219   \n",
       "\n",
       "   fsCT_R_p24_ROI  \n",
       "0           3.179  \n",
       "1           3.324  \n",
       "2           3.232  \n",
       "3           3.264  \n",
       "4           4.128  \n",
       "\n",
       "[5 rows x 1446 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read_csv can read in just about any plain-text tabular data\n",
    "data = pd.read_csv('./data/abide2.tsv', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223fc099",
   "metadata": {},
   "source": [
    "You may recognize this data from Tal's tutorial introducing machine learning!\n",
    "\n",
    "For our purposes, what's most interesting is the structure of this data set.\n",
    "That is, the data is structured in a tabular format,\n",
    "with pre-extracted features of interest.\n",
    "This makes it easier to consider issues such as: which features would we like to predict?\n",
    "Or, how should we handle cross-validation?\n",
    "\n",
    "But if we're starting with neuroimaging data,\n",
    "how can create this kind of structured representation?\n",
    "\n",
    "## Neuroimaging data\n",
    "\n",
    "Neuroimaging data does not have a tabular structure.\n",
    "Instead, it has both spatial and temporal dependencies between successive data points.\n",
    "That is, knowing _where_ and _when_ something was measured tells you information about the surrounding data points.\n",
    "\n",
    "We also know that neuroimaging data contains a lot of noise that's not blood-oxygen-level dependent (BOLD), such as head motion.\n",
    "Since we don't think that these other noise sources are related to neuronal firing,\n",
    "we often need to consider how we can make sure that our analyses are not driven by these noise sources.\n",
    "\n",
    "These are all considerations that most machine learning software libraries are not designed to deal with!\n",
    "Nilearn therefore plays a crucial role in bringing machine learning concepts to the neuroimaging domain.\n",
    "\n",
    "To get a sense of the problem, the quickest method is to just look at some data.\n",
    "You may have your own data locally that you'd like to work with.\n",
    "Nilearn also provides access to several neuroimaging data sets and atlases (we'll talk about these a bit later).\n",
    "\n",
    "These data sets (and atlases) are only accessible because research groups chose to make their collected data publicly available.\n",
    "We owe them a huge thank you for this!\n",
    "The data set we'll use today was originally collected by [Rebecca Saxe](https://mcgovern.mit.edu/profile/rebecca-saxe/)'s group at MIT and hosted on [OpenNeuro](https://openneuro.org/datasets/ds000228/versions/1.1.0).\n",
    "\n",
    "The nilearn team preprocessed the data set with [fMRIPrep](https://fmriprep.readthedocs.io) and downsampled it to a lower resolution,\n",
    "so it'd be easier to work with.\n",
    "We can learn a lot about this data set directly [from the Nilearn documentation](https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_development_fmri.html).\n",
    "For example, we can see that this data set contains over 150 children and adults watching a short Pixar film.\n",
    "Let's download the first 30 participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3194583c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/nilearn/__init__.py:69: FutureWarning: Python 3.7 support is deprecated and will be removed in release 0.12 of Nilearn. Consider switching to Python 3.9 or 3.10.\n",
      "  _python_deprecation_warnings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created in /home/runner/nilearn_data/development_fmri\n",
      "\n",
      "\n",
      "Dataset created in /home/runner/nilearn_data/development_fmri/development_fmri\n",
      "\n",
      "Downloading data from https://osf.io/yr3av/download ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3df4712b400183b7092/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e04712b400193b5bdf/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e14712b400183b7097/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e32286e80018c3e42c/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e4a743a9001760814f/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e54712b400183b70a5/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e52286e80018c3e439/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e72286e80017c41b3d/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e9a743a90017608158/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3e82286e80018c3e443/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3ea4712b400183b70b7/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3eb2286e80019c3c194/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff37da743a90018606df1/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff37c2286e80019c3c102/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb4701e3992690018133d4f/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5cb46e6b353c58001b9cb34f/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff37d4712b400193b5b54/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff37d4712b400183b7011/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff37e2286e80016c3c2cb/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3832286e80019c3c10f/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3822286e80018c3e37b/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff382a743a90018606df8/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3814712b4001a3b5561/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3832286e80016c3c2d1/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (2 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3842286e80017c419e0/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://osf.io/download/5c8ff3854712b4001a3b5568/ ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1741/2236572832.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdevelopment_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_development_fmri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_subjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/nilearn/datasets/func.py\u001b[0m in \u001b[0;36mfetch_development_fmri\u001b[0;34m(n_subjects, reduce_confounds, data_dir, resume, verbose, age_group)\u001b[0m\n\u001b[1;32m   1626\u001b[0m                                                            \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                                                            \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m                                                            verbose=verbose)\n\u001b[0m\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduce_confounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/nilearn/datasets/func.py\u001b[0m in \u001b[0;36m_fetch_development_fmri_functional\u001b[0;34m(participants, data_dir, url, resume, verbose)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                       {'move': func.format(participant_id)})]\n\u001b[1;32m   1506\u001b[0m         path_to_func = _fetch_files(data_dir, func_file, resume=resume,\n\u001b[0;32m-> 1507\u001b[0;31m                                     verbose=verbose)[0]\n\u001b[0m\u001b[1;32m   1508\u001b[0m         \u001b[0mfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/nilearn/datasets/utils.py\u001b[0m in \u001b[0;36m_fetch_files\u001b[0;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[1;32m    730\u001b[0m             return _fetch_files(\n\u001b[1;32m    731\u001b[0m                 \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                 verbose=verbose, session=session)\n\u001b[0m\u001b[1;32m    733\u001b[0m     \u001b[0;31m# There are two working directories here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;31m# - data_dir is the destination directory of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/nilearn/datasets/utils.py\u001b[0m in \u001b[0;36m_fetch_files\u001b[0;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[1;32m    781\u001b[0m                                   \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'username'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                                   \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'password'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                                   session=session, overwrite=overwrite)\n\u001b[0m\u001b[1;32m    784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'move'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m# XXX: here, move is supposed to be a dir, it can be a name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/nilearn/datasets/utils.py\u001b[0m in \u001b[0;36m_fetch_file\u001b[0;34m(url, data_dir, resume, overwrite, md5sum, username, password, verbose, session)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mprepped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             with session.send(\n\u001b[0;32m--> 620\u001b[0;31m                     prepped, stream=True, timeout=_REQUESTS_TIMEOUT) as resp:\n\u001b[0m\u001b[1;32m    621\u001b[0m                 \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_full_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                     \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0madapter_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                 )\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                 )\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "development_dataset = datasets.fetch_development_fmri(n_subjects=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d5518",
   "metadata": {},
   "source": [
    "Now, this `development_dataset` object has several attributes which provide access to the relevant information.\n",
    "For example, `development_dataset.phenotypic` provides access to information about the participants, such as whether they were children or adults.\n",
    "We can use `development_dataset.func` to access the functional MRI (fMRI) data.\n",
    "\n",
    "Let's use the [nibabel library](https://nipy.org/nibabel/) to learn a little bit about this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(development_dataset.func[0])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a2a4a",
   "metadata": {},
   "source": [
    "This means that there are 168 volumes, each with a 3D structure of (50, 59, 50).\n",
    "\n",
    "## Getting into the data: subsetting and viewing\n",
    "\n",
    "Nilearn also provides many methods for plotting this kind of data.\n",
    "For example, we can use [`nilearn.plotting.view_img`](https://nilearn.github.io/modules/generated/nilearn.plotting.view_img.html) to launch at interactive viewer.\n",
    "Because each fMRI run is a 4D time series (three spatial dimensions plus time),\n",
    "we'll also need to subset the data when we plot it, so that we can look at a single 3D image.\n",
    "Nilearn provides (at least) two ways to do this: with [`nilearn.image.index_img`](https://nilearn.github.io/modules/generated/nilearn.image.index_img.html),\n",
    "which allows us to index a particular frame--or several frames--of a time series,\n",
    "and [`nilearn.image.mean_img`](https://nilearn.github.io/modules/generated/nilearn.image.mean_img.html),\n",
    "which allows us to take the mean 3D image over time.\n",
    "\n",
    "Putting these together, we can interatively view the mean image of the first participant using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da676bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "\n",
    "mean_image = image.mean_img(development_dataset.func[0])\n",
    "plotting.view_img(mean_image, threshold=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6674677",
   "metadata": {},
   "source": [
    "## Extracting signal from fMRI volumes\n",
    "\n",
    "As you can see, this data is decidedly not tabular!\n",
    "What we'd like is to extract and transform meaningful features from this data,\n",
    "and store it in a format that we can easily work with.\n",
    "Importantly, we _could_ work with the full time series directly.\n",
    "But we often want to reduce the dimensionality of our data in a structured way.\n",
    "That is, we may only want to consider signal within certain learned or pre-defined regions of interest (ROIs),\n",
    "and when taking into account known sources of noise.\n",
    "To do this, we'll use nilearn's Masker objects.\n",
    "What are the masker objects ?\n",
    "First, let's think about what masking fMRI data is doing:\n",
    "\n",
    "```{figure} ../images/masking.jpg\n",
    "---\n",
    "height: 350px\n",
    "name: masking\n",
    "---\n",
    "Masking fMRI data.\n",
    "```\n",
    "\n",
    "Essentially, we can imagine overlaying a 3D grid on an image.\n",
    "Then, our mask tells us which cubes or “voxels” (like 3D pixels) to sample from.\n",
    "Since our Nifti images are 4D files, we can’t overlay a single grid –\n",
    "instead, we use a series of 3D grids (one for each volume in the 4D file),\n",
    "so we can get a measurement for each voxel at each timepoint.\n",
    "\n",
    "Masker objects allow us to apply these masks!\n",
    "To start, we need to define a mask (or masks) that we'd like to apply.\n",
    "This could correspond to one or many regions of interest.\n",
    "Nilearn provides methods to define your own functional parcellation (using clustering algorithms such as _k-means_),\n",
    "and it also provides access to other atlases that have previously been defined by researchers.\n",
    "\n",
    "## Choosing regions of interest\n",
    "\n",
    "In this tutorial,\n",
    "we'll use the MSDL (multi-subject dictionary learning; {cite}`Varoquaux_2011`) atlas,\n",
    "which defines a set of _probabilistic_ ROIs across the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "msdl_atlas = datasets.fetch_atlas_msdl()\n",
    "\n",
    "msdl_coords = msdl_atlas.region_coords\n",
    "n_regions = len(msdl_coords)\n",
    "\n",
    "print(f'MSDL has {n_regions} ROIs, part of the following networks :\\n{np.unique(msdl_atlas.networks)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d334856e",
   "metadata": {},
   "source": [
    "Nilearn ships with several atlases commonly used in the field,\n",
    "including the Schaefer atlas and the Harvard-Oxford atlas.\n",
    "\n",
    "It also provides us with easy ways to view these atlases directly.\n",
    "Because MSDL is a probabilistic atlas, we can view it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_prob_atlas(msdl_atlas.maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ba152",
   "metadata": {},
   "source": [
    "## A quick side-note on the NiftiMasker zoo\n",
    "\n",
    "We'd like to supply these ROIs to a Masker object.\n",
    "All Masker objects share the same basic structure and functionality,\n",
    "but each is designed to work with a different kind of ROI.\n",
    "\n",
    "The canonical [`nilearn.maskers.NiftiMasker`](https://nilearn.github.io/modules/generated/nilearn.maskers.NiftiMasker.html) works well if we want to apply a single mask to the data,\n",
    "like a single region of interest.\n",
    "\n",
    "But what if we actually have several ROIs that we'd like to apply to the data all at once?\n",
    "If these ROIs are non-overlapping,\n",
    "as in \"hard\" or deterministic parcellations,\n",
    "then we can use [`nilearn.maskers.NiftiLabelsMasker`](https://nilearn.github.io/modules/generated/nilearn.maskers.NiftiLabelsMasker.html).\n",
    "Because we're working with \"soft\" or probabilistic ROIs,\n",
    "we can instead supply these ROIs to [`nilearn.maskers.NiftiMapsMasker`](https://nilearn.github.io/modules/generated/nilearn.maskers.NiftiMapsMasker.html).\n",
    "\n",
    "For a full list of the available Masker objects,\n",
    "see [the Nilearn documentation](https://nilearn.github.io/modules/reference.html#module-nilearn.maskers).\n",
    "\n",
    "## Applying a Masker object\n",
    "\n",
    "We can supply our MSDL atlas-defined ROIs to the `NiftiMapsMasker` object,\n",
    "along with resampling, filtering, and detrending parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import maskers\n",
    "\n",
    "masker = maskers.NiftiMapsMasker(\n",
    "    msdl_atlas.maps, resampling_target=\"data\",\n",
    "    t_r=2, detrend=True,\n",
    "    low_pass=0.1, high_pass=0.01).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d5274",
   "metadata": {},
   "source": [
    "One thing you might notice from the above code is that immediately after defining the masker object,\n",
    "we call the `.fit` method on it.\n",
    "This method may look familiar if you've previously worked with scikit-learn estimators!\n",
    "\n",
    "You'll note that we're not supplying any data to this `.fit` method;\n",
    "that's because we're fitting the Masker to the provided ROIs, rather than to our data.\n",
    "\n",
    "## Dimensions, dimensions\n",
    "\n",
    "We can use this fitted masker to transform our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_time_series = masker.transform(development_dataset.func[0])\n",
    "roi_time_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec7d07",
   "metadata": {},
   "source": [
    "If you'll remember, when we first looked at the data its original dimensions were (50, 59, 50, 168).\n",
    "Now, it has a shape of (168, 39).\n",
    "What happened?!\n",
    "\n",
    "Rather than providing information on every voxel within our original 3D grid,\n",
    "we're now only considering those voxels that fall in our 39 regions of interest provided by the MSDL atlas and aggregating across voxels within those ROIS.\n",
    "This reduces each 3D volume from a dimensionality of (50, 59, 50) to just 39,\n",
    "for our 39 provided ROIs.\n",
    "\n",
    "You'll also see that the \"dimensions flipped;\"\n",
    "that is, that we've transposed the matrix such that time is now the first rather than second dimension.\n",
    "This follows the scikit-learn convention that rows in a data matrix are _samples_,\n",
    "and columns in a data matrix are _features_.\n",
    "\n",
    "```{figure} ../images/samples-features.png\n",
    "---\n",
    "height: 250px\n",
    "name: samples-features\n",
    "---\n",
    "The scikit-learn conventions for feature and target matrices.\n",
    "From Jake VanderPlas's _Python Data Science Handbook_.\n",
    "```\n",
    "\n",
    "One of the nice things about working with nilearn is that it will impose this convention for you,\n",
    "so you don't accidentally flip your dimensions when using a scikit-learn model!\n",
    "\n",
    "## Creating and viewing a connectome\n",
    "\n",
    "The simplest and most commonly used kind of functional connectivity is pairwise correlation between ROIs.\n",
    "We can estimate it using [`nilearn.connectome.ConnectivityMeasure`](https://nilearn.github.io/modules/generated/nilearn.connectome.ConnectivityMeasure.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41820b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrix = correlation_measure.fit_transform([roi_time_series])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe7c19",
   "metadata": {},
   "source": [
    "We can then plot this functional connectivity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(correlation_matrix, 0)\n",
    "plotting.plot_matrix(correlation_matrix, labels=msdl_atlas.labels,\n",
    "                     vmax=0.8, vmin=-0.8, colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac5ba9",
   "metadata": {},
   "source": [
    "Or view it as an embedded connectome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_connectome(correlation_matrix, edge_threshold=0.2,\n",
    "                         node_coords=msdl_atlas.region_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f9bcd",
   "metadata": {},
   "source": [
    "## Accounting for noise sources\n",
    "\n",
    "As we've already seen,\n",
    "maskers also allow us to perform other useful operations beyond just masking our data.\n",
    "One important processing step is correcting for measured signals of no interest (e.g., head motion).\n",
    "Our `development_dataset` also includes several of these signals of no interest that were generated during fMRIPrep pre-processing.\n",
    "We can access these with the `confounds` attribute,\n",
    "using `development_dataset.confounds`.\n",
    "\n",
    "Let's quickly check what these look like for our first participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(development_dataset.confounds[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101dbbba",
   "metadata": {},
   "source": [
    "We can see that there are several different kinds of noise sources included!\n",
    "This is actually a subset of all possible fMRIPrep generated confounds that the Nilearn developers have pre-selected.\n",
    "We could access the full list by passing the argument `reduce_confounds=False` to our original call downloading the `development_dataset`.\n",
    "For most analyses, this list of confounds is reasonable, so we'll use these Nilearn provided defaults.\n",
    "For your own analyses, make sure to check which confounds you're using!\n",
    "\n",
    "Importantly, we can pass these confounds directly to our masker object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_roi_time_series = masker.transform(\n",
    "    development_dataset.func[0], confounds=development_dataset.confounds[0])\n",
    "corrected_correlation_matrix = correlation_measure.fit_transform(\n",
    "    [corrected_roi_time_series])[0]\n",
    "np.fill_diagonal(corrected_correlation_matrix, 0)\n",
    "plotting.plot_matrix(corrected_correlation_matrix, labels=msdl_atlas.labels,\n",
    "                     vmax=0.8, vmin=-0.8, colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c142aab",
   "metadata": {},
   "source": [
    "As before, we can also view this functional connectivity matrix as a connectome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ca781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_connectome(corrected_correlation_matrix, edge_threshold=0.2,\n",
    "                         node_coords=msdl_atlas.region_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcd1ce",
   "metadata": {},
   "source": [
    "In both the matrix and connectome forms,\n",
    "we can see a big difference when including the confounds!\n",
    "This is an important reminder to make sure that your data are cleaned of any possible sources of noise _before_ running a machine learning analysis.\n",
    "Otherwise, you might be classifying participants on e.g. amount of head motion rather than a feature of interest!\n",
    "\n",
    "```{bibliography} references.bib\n",
    ":style: unsrt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "repository": {
   "url": "https://github.com/emdupre/nha2020-nilearn"
  },
  "source_map": [
   10,
   14,
   19,
   35,
   41,
   81,
   86,
   94,
   99,
   116,
   123,
   164,
   173,
   181,
   183,
   209,
   216,
   229,
   232,
   265,
   270,
   274,
   278,
   282,
   285,
   298,
   300,
   310,
   318,
   322,
   325
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}