{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5457b5e6",
   "metadata": {},
   "source": [
    "# Statistical analysis in `nilearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f9f62",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc509a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import datasets\n",
    "\n",
    "os.environ[\"NILEARN_SHARED_DATA\"] = \"~/shared/data/nilearn_data\"\n",
    "datasets.get_data_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf9bbf",
   "metadata": {},
   "source": [
    "In the previous examples, we've generated connectivity matrices as our features-of-interest for machine learning.\n",
    "However, there are many other kinds of relevant features we may want to extract from neuroimaging data.\n",
    "Alternatively, we may not be interested in doing machine learning at all,\n",
    "but instead performing statistical analysis using methods such as the General Linear Model (GLM).\n",
    "\n",
    "In this example, we'll perform a GLM analysis of a dataset provided by the Haxby Lab,\n",
    "in which participants were shown a number different categories of visual images {cite}`Haxby2001-sr`.\n",
    "\n",
    "In this example, we'll focus on within-participant analyses, taking advantage of the large number of stimuli each participant saw.\n",
    "In reviewing this material, I'd encourage you to try to change the participant used in this example to see how the results change !\n",
    "\n",
    "## Accessing and understanding the Haxby dataset\n",
    "\n",
    "First, we need to download the dataset and its associated stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c06f206",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn.datasets import fetch_haxby\n",
    "\n",
    "haxby_dataset = fetch_haxby(subjects=(2,), fetch_stimuli=True)\n",
    "\n",
    "# set TR in seconds, following information in the original paper\n",
    "t_r = 2.5\n",
    "print(haxby_dataset.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5af419",
   "metadata": {},
   "source": [
    "Much as for the `development_dataset`, this `haxby_dataset` has several attributes that will be of interest for our analyses.\n",
    "For example, `haxby_dataset.mask` provides access to the brain mask used in the original experiments.\n",
    "We can use `haxby_dataset.func` to access the functional MRI (fMRI) data, one nii file for each participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be83b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn import image, plotting\n",
    "\n",
    "mean_img_ = image.mean_img(haxby_dataset.func[0], copy_header=True)\n",
    "plotting.plot_epi(mean_img_)\n",
    "\n",
    "n_trs = nib.load(haxby_dataset.func[0]).shape[-1]\n",
    "print(f\"There are {n_trs} TRs in the file {haxby_dataset.func[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a720bd4",
   "metadata": {},
   "source": [
    "Unlike the `development_dataset`, the `haxby_dataset` also two additional attributes that are relevant for fitting our GLM.\n",
    "First, `haxby_dataset.stimuli` allows us to access the original stimuli included in the experiment.\n",
    "We will view a single image for each of the eight presented visual categories, to get an intuition for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "key_stimuli = []\n",
    "exp_stimuli = []\n",
    "for key, values in haxby_dataset.stimuli.items():\n",
    "    key_stimuli.append(key)\n",
    "\n",
    "    try:\n",
    "        exp_stimuli.append(values[0])\n",
    "    except KeyError:\n",
    "        exp_stimuli.append(values['scrambled_faces'][0])\n",
    "\n",
    "# update naming convention of 'controls' to match labels in behavioral csv\n",
    "key_stimuli[4] = 'scrambledpix' \n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(12, 12))\n",
    "# fig.suptitle(\"Example stimuli used in the experiment\")\n",
    "\n",
    "for img_path, img_categ, ax in zip(exp_stimuli, key_stimuli, axes.ravel()):\n",
    "    ax.imshow(plt.imread(img_path), cmap=\"gray\")\n",
    "    ax.set_title(img_categ)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed63ea50",
   "metadata": {},
   "source": [
    "The second attribute that `haxby_dataset` has that will be of special interest to our GLM analyses is `haxby_dataset.session_target`.\n",
    "This provides the path to a CSV file, one per each participant.\n",
    "Let's load and view one CSV file to get a sense of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eadfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target information as string \n",
    "events = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f89d7",
   "metadata": {},
   "source": [
    "You may notice that the two columns in the CSV are `labels` and `chunks`.\n",
    "As all runs have been concatenated into a single nii file, the run identifier is indicated in the `chunk` label.\n",
    "Each entry in the CSV corresponds to the presentation of a single image, whose visual category is given by the `label` identifier.\n",
    "\n",
    "We can identify the unique runs and visual categories in this `session_target` CSV and compare them against our known stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_conditions = events[\"labels\"].unique()\n",
    "conditions = events[\"labels\"].values\n",
    "print(unique_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record these as an array of runs\n",
    "runs = events[\"chunks\"].to_numpy()\n",
    "unique_runs = events[\"chunks\"].unique()\n",
    "print(unique_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadeb6b8",
   "metadata": {},
   "source": [
    "Using this information, we can create a model of our knowledge of events that occurred during the functional run.\n",
    "In general, there are many different ways to define these events:\n",
    "\n",
    "```{figure} ../images/stimulation-time-diagram.png\n",
    "---\n",
    "height: 250px\n",
    "name: stimulation-time-diagram\n",
    "---\n",
    "From the [Nilearn User guide](https://nilearn.github.io/stable/glm/glm_intro.html),\n",
    "this image illustrates how we can think about a single fMRI run as comprised of different events.\n",
    "We know, though, that the fMRI signal contains both neural and non-neural information,\n",
    "so we do not expect our fMRI time courses to neatly follow this event structure!\n",
    "Still, this understanding can be useful for modelling the signal.\n",
    "```\n",
    "\n",
    "Note that the structure of our CSVs means that each image was presented for a full TR, without any jitter in the presentation.\n",
    "\n",
    "## Understanding the General Linear Model\n",
    "\n",
    "The General Linear Model (GLM) can be understood using the following formula :\n",
    "\n",
    "$$\n",
    "Y = \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n + \\epsilon\n",
    "$$\n",
    "\n",
    "This tells us that :\n",
    "- we're going to model each voxels observed activity, $Y$, as \n",
    "- a linear combination of $n$ regressors $X$, each of which \n",
    "- are weighted by a unique parameter estimate, $\\beta$.\n",
    "- We also include an error term, $\\epsilon$, which is the residual information not captured by our regressors.\n",
    "\n",
    "In order to fit this model, therefore, we need our $Y$ and our $X$'s.\n",
    "We have access to $Y$ through the `haxby_dataset.func` attribute, though we of course need to get it into a reasonable format for machine learning and statistical analysis (as discussed in the previous tutorials).\n",
    "To define our $X$ values, we will create \"design matrices,\" which include both timing information of the events of interest, as well as information on known sources of noise, such as cosine regressors or other confounds.\n",
    "\n",
    "## Generate design matrices for each run\n",
    "\n",
    "Now that we understand the structure of our dataset, we will use this information to generate \"design matrices\" for each run to use in our GLM.\n",
    "For each run, let's quickly create a `pandas.DataFrame` with minimal timing information, including only the frame times, the trial type (i.e., the visual category), and the duration.\n",
    "We'll gather all of these dataframes into a dictionary, with run indices as the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1491412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events will take the form of a dictionary of Dataframes, one per run\n",
    "events = {}\n",
    "\n",
    "for run in unique_runs:\n",
    "\n",
    "    # get the condition label per run\n",
    "    conditions_run = conditions[runs == run]\n",
    "\n",
    "    # get the number of scans per run, then the corresponding\n",
    "    # vector of frame times\n",
    "    n_scans = len(conditions_run)\n",
    "    frame_times = t_r * np.arange(n_scans)\n",
    "\n",
    "    # each event lasts the full TR\n",
    "    duration = t_r * np.ones(n_scans)\n",
    "\n",
    "    # Define the events object\n",
    "    events_ = pd.DataFrame(\n",
    "        {\n",
    "            \"onset\": frame_times,\n",
    "            \"trial_type\": conditions_run,\n",
    "            \"duration\": duration,\n",
    "        }\n",
    "    )\n",
    "    # remove the rest condition and insert into the dictionary\n",
    "    # this will be our baseline in the GLM, so we don't want to model it as a condition\n",
    "    events[run] = events_[events_.trial_type != \"rest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03100cdd",
   "metadata": {},
   "source": [
    "Now we can view one of these minimal timing information, just to see its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a062418",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f542ec",
   "metadata": {},
   "source": [
    "Nilearn also provides some nice functionality to convert this into a design matrix and view it in a more familar format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "\n",
    "X1 = make_first_level_design_matrix(\n",
    "    events[0].onset.values,\n",
    "    events[0],\n",
    "    drift_model=\"cosine\",\n",
    "    high_pass=0.008,\n",
    "    hrf_model=\"glover\",\n",
    ")\n",
    "plotting.plot_design_matrix(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b60fc4",
   "metadata": {},
   "source": [
    "One thing to note: You may remember from our previous example with `development_dataset` that it's really important to include confound information such as head motion.\n",
    "Unfortunately, this dataset is older (published in 2001! {cite}`Haxby2001-sr`) and so its head motion information is no longer available.\n",
    "In real data, you want to make sure to include confound information when you create your design matrices.\n",
    "\n",
    "## Run First-Level General Linear Models (GLMs)\n",
    "\n",
    "We are now ready to run our General Linear Models using Nilearn !\n",
    "Since we are working with within-participant data, these will be \"first-level\" models, which reflect only within-participant information.\n",
    "Nilearn makes this very easy for us.\n",
    "In particular, we can instantiate the `FirstLevelModel` estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee81a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "z_maps = []\n",
    "conditions_label = []\n",
    "run_label = []\n",
    "\n",
    "# Instantiate the glm\n",
    "glm = FirstLevelModel(\n",
    "    t_r=t_r,\n",
    "    mask_img=haxby_dataset.mask,\n",
    "    high_pass=0.008,\n",
    "    smoothing_fwhm=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d9e31",
   "metadata": {},
   "source": [
    "Then our analysis is as simple as passing our functional image and our minimal timing information!\n",
    "To learn about the processing of each visual category, we will also use the `compute_contrast` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51968fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img\n",
    "\n",
    "for run in unique_runs:\n",
    "    # grab the fmri data for that particular run\n",
    "    fmri_run = index_img(haxby_dataset.func[0], runs == run)\n",
    "\n",
    "    # fit the GLM\n",
    "    glm.fit(fmri_run, events=events[run])\n",
    "\n",
    "    # set up contrasts: one per condition\n",
    "    conditions = events[run].trial_type.unique()\n",
    "    for condition_ in conditions:\n",
    "        z_maps.append(glm.compute_contrast(condition_))\n",
    "        conditions_label.append(condition_)\n",
    "        run_label.append(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a1ce54",
   "metadata": {},
   "source": [
    "Finally, we can check the generated report structure to learn about the GLM, including its design matrices and computed contrasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = glm.generate_report(\n",
    "    contrasts=conditions,\n",
    "    bg_img=mean_img_,\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0de37",
   "metadata": {},
   "source": [
    "```{bibliography} references.bib\n",
    ":style: unsrt\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   16,
   22,
   29,
   46,
   58,
   64,
   73,
   79,
   104,
   110,
   114,
   122,
   128,
   133,
   176,
   204,
   208,
   210,
   214,
   225,
   238,
   252,
   257,
   273,
   277,
   283
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}